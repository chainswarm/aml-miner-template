{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Analysis\n",
    "\n",
    "**Purpose**: Analyze engineered features for model training\n",
    "\n",
    "This notebook helps you:\n",
    "- Build features using FeatureBuilder\n",
    "- Analyze feature distributions\n",
    "- Detect correlations and multicollinearity\n",
    "- Identify outliers\n",
    "- Validate feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from packages.training import FeatureExtractor, FeatureBuilder, ModelTrainer\n",
    "from packages.storage import ClientFactory, get_connection_params\n",
    "from notebook_utils import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from loguru import logger\n",
    "from scipy import stats\n",
    "\n",
    "setup_plotting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETWORK = 'ethereum'\n",
    "START_DATE = '2024-01-01'\n",
    "END_DATE = '2024-01-31'\n",
    "WINDOW_DAYS = 7\n",
    "\n",
    "print(f\"Network: {NETWORK}\")\n",
    "print(f\"Date Range: {START_DATE} to {END_DATE}\")\n",
    "print(f\"Window: {WINDOW_DAYS} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_params = get_connection_params(NETWORK)\n",
    "client_factory = ClientFactory(connection_params)\n",
    "\n",
    "with client_factory.client_context() as client:\n",
    "    extractor = FeatureExtractor(client)\n",
    "    data = extractor.extract_training_data(\n",
    "        start_date=START_DATE,\n",
    "        end_date=END_DATE,\n",
    "        window_days=WINDOW_DAYS\n",
    "    )\n",
    "\n",
    "print(f\"Extracted data shape: {data.shape}\")\n",
    "print(f\"Columns: {data.columns.tolist()[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = FeatureBuilder()\n",
    "X, y = builder.build_training_features(data)\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeatures: {X.columns.tolist()[:15]}...\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = X.columns.tolist()\n",
    "print(f\"Total features: {len(feature_cols)}\")\n",
    "\n",
    "if len(feature_cols) >= 6:\n",
    "    plot_feature_distributions(X, feature_cols[:6])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(feature_cols) >= 12:\n",
    "    plot_feature_distributions(X, feature_cols[6:12])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = X.isnull().sum()\n",
    "missing_pct = (missing / len(X) * 100).round(2)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(\"Features with missing values:\")\n",
    "    print(missing_df)\n",
    "else:\n",
    "    print(\"No missing values found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(feature_cols) <= 30:\n",
    "    plot_correlation_matrix(X, figsize=(14, 12))\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Too many features ({len(feature_cols)}) for full correlation matrix\")\n",
    "    print(\"Showing correlation for first 20 features:\")\n",
    "    plot_correlation_matrix(X[feature_cols[:20]], figsize=(14, 12))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Correlation Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = X.corr().abs()\n",
    "upper_triangle = corr_matrix.where(\n",
    "    np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    ")\n",
    "\n",
    "high_corr = [(column, row, upper_triangle.loc[row, column])\n",
    "             for column in upper_triangle.columns\n",
    "             for row in upper_triangle.index\n",
    "             if upper_triangle.loc[row, column] > 0.8]\n",
    "\n",
    "if high_corr:\n",
    "    print(f\"Found {len(high_corr)} feature pairs with correlation > 0.8:\")\n",
    "    for feat1, feat2, corr_val in sorted(high_corr, key=lambda x: x[2], reverse=True)[:10]:\n",
    "        print(f\"  {feat1} <-> {feat2}: {corr_val:.3f}\")\n",
    "else:\n",
    "    print(\"No highly correlated features found (threshold: 0.8)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_summary = []\n",
    "\n",
    "for col in feature_cols[:10]:\n",
    "    Q1 = X[col].quantile(0.25)\n",
    "    Q3 = X[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = ((X[col] < lower_bound) | (X[col] > upper_bound)).sum()\n",
    "    outlier_pct = (outliers / len(X) * 100).round(2)\n",
    "    \n",
    "    outlier_summary.append({\n",
    "        'Feature': col,\n",
    "        'Outliers': outliers,\n",
    "        'Percentage': outlier_pct\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary).sort_values('Percentage', ascending=False)\n",
    "print(\"Outlier Summary (first 10 features):\")\n",
    "print(outlier_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Plots for Outlier Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(feature_cols) >= 6:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, col in enumerate(feature_cols[:6]):\n",
    "        axes[idx].boxplot(X[col].dropna())\n",
    "        axes[idx].set_title(f'{col}')\n",
    "        axes[idx].set_ylabel('Value')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ranges = pd.DataFrame({\n",
    "    'Feature': feature_cols[:10],\n",
    "    'Min': [X[col].min() for col in feature_cols[:10]],\n",
    "    'Max': [X[col].max() for col in feature_cols[:10]],\n",
    "    'Mean': [X[col].mean() for col in feature_cols[:10]],\n",
    "    'Std': [X[col].std() for col in feature_cols[:10]]\n",
    "})\n",
    "\n",
    "print(\"Feature Scaling Summary (first 10 features):\")\n",
    "print(feature_ranges.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Distribution by Target Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(feature_cols) >= 4:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, col in enumerate(feature_cols[:4]):\n",
    "        for class_val in y.unique()[:2]:\n",
    "            mask = y == class_val\n",
    "            axes[idx].hist(X.loc[mask, col], bins=30, alpha=0.6, label=f'Class {class_val}')\n",
    "        \n",
    "        axes[idx].set_title(f'{col} by Target Class')\n",
    "        axes[idx].set_xlabel('Value')\n",
    "        axes[idx].set_ylabel('Frequency')\n",
    "        axes[idx].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Preview (Correlation with Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_with_target = X.copy()\n",
    "X_with_target['target'] = y\n",
    "\n",
    "target_corr = X_with_target.corr()['target'].drop('target').abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 15 features by correlation with target:\")\n",
    "print(target_corr.head(15).round(4))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "target_corr.head(15).plot(kind='barh')\n",
    "plt.title('Top 15 Features by Absolute Correlation with Target')\n",
    "plt.xlabel('Absolute Correlation')\n",
    "plt.ylabel('Feature')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plots for Top Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = target_corr.head(4).index.tolist()\n",
    "\n",
    "if len(top_features) >= 4:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, feat in enumerate(top_features):\n",
    "        for class_val in y.unique()[:2]:\n",
    "            mask = y == class_val\n",
    "            axes[idx].scatter(X.loc[mask, feat], y[mask], alpha=0.5, label=f'Class {class_val}')\n",
    "        \n",
    "        axes[idx].set_title(f'{feat} vs Target')\n",
    "        axes[idx].set_xlabel(feat)\n",
    "        axes[idx].set_ylabel('Target')\n",
    "        axes[idx].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "**Key Findings**:\n",
    "\n",
    "1. **Feature Quality**: Review missing values and outliers\n",
    "2. **Multicollinearity**: Check for highly correlated features\n",
    "3. **Scaling**: Understand feature value ranges\n",
    "4. **Predictive Power**: Identify features correlated with target\n",
    "5. **Class Separation**: Analyze feature distributions by class\n",
    "\n",
    "**Next Steps**:\n",
    "- Remove or combine highly correlated features\n",
    "- Handle outliers if necessary\n",
    "- Proceed to Model Training notebook\n",
    "- Consider feature selection strategies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}